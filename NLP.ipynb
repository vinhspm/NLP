{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import re\n",
    "import numpy as np\n",
    "from pyvi import ViTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"trainning.txt\", encoding='UTF-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for i in range(len(lines)):\n",
    "    lines[i] = lines[i].split('\\t')\n",
    "X = []\n",
    "Y = []\n",
    "for line in lines:\n",
    "    if(len(line) == 2):\n",
    "        X.append(line[1])\n",
    "        Y.append(line[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_lines = []\n",
    "for line in X:\n",
    "    line = gensim.utils.simple_preprocess(line)\n",
    "    for i in range(len(line)):\n",
    "        line[i].lower()\n",
    "    line = ' '.join(line)\n",
    "    line = ViTokenizer.tokenize(line)\n",
    "    gensim.parsing.preprocessing.remove_stopwords(line)\n",
    "    processed_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(processed_lines)):\n",
    "    processed_lines[i] = processed_lines[i].split(' ')\n",
    "    processed_lines[i] = list(dict.fromkeys(processed_lines[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wordList = []\n",
    "filePath = 'wordListtesting.npy'\n",
    "if os.path.isfile(filePath) is False:\n",
    "    for line in processed_lines:\n",
    "        for word in line:\n",
    "            if word not in wordList:\n",
    "                wordList.append(word)\n",
    "    wordList = np.array(wordList)\n",
    "    f = open(filePath, 'wb+')\n",
    "    np.save(filePath,wordList)\n",
    "    f.close()\n",
    "else:\n",
    "    f = open(filePath)\n",
    "    wordList = np.load(filePath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "40550\n"
    }
   ],
   "source": [
    "print(len(wordList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filePath = 'X_words.npy'\n",
    "if os.path.isfile(filePath) is False:\n",
    "    for i in range(len(X)):\n",
    "        X[i].lower()\n",
    "        X[i] = gensim.utils.simple_preprocess(X[i])\n",
    "        X[i] = ' '.join(X[i])\n",
    "        X[i] = ViTokenizer.tokenize(X[i])\n",
    "        gensim.parsing.preprocessing.remove_stopwords(X[i])\n",
    "        X[i] = X[i].split(' ')\n",
    "    X = np.array(X)\n",
    "    f = open(filePath, 'wb+')\n",
    "    np.save(filePath,X)\n",
    "    f.close()\n",
    "else:\n",
    "    f = open(filePath)\n",
    "    X = np.load(filePath, allow_pickle = True)\n",
    "\n"
   ]
  },
  {
   "source": [
    "\n",
    "print(X[0])"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[&#39;gần&#39;, &#39;học_sinh&#39;, &#39;phải&#39;, &#39;học&#39;, &#39;trong&#39;, &#39;điều_kiện&#39;, &#39;tạm_bợ&#39;, &#39;nlđ&#39;, &#39;gần&#39;, &#39;học_sinh&#39;, &#39;trường&#39;, &#39;tiểu_học&#39;, &#39;đống&#39;, &#39;đa&#39;, &#39;quận&#39;, &#39;bình&#39;, &#39;thạnh&#39;, &#39;tphcm&#39;, &#39;đến&#39;, &#39;nay&#39;, &#39;vẫn&#39;, &#39;phải&#39;, &#39;được&#39;, &#39;gởi&#39;, &#39;học&#39;, &#39;tạm&#39;, &#39;tại&#39;, &#39;nơi&#39;, &#39;cách&#39;, &#39;nhà&#39;, &#39;khoảng&#39;, &#39;km&#39;, &#39;do&#39;, &#39;ngôi&#39;, &#39;trường&#39;, &#39;này&#39;, &#39;đã&#39;, &#39;xuống_cấp&#39;, &#39;trầm_trọng&#39;, &#39;theo&#39;, &#39;kế_hoạch&#39;, &#39;đầu&#39;, &#39;năm_học&#39;, &#39;trường&#39;, &#39;tiểu_học&#39;, &#39;đống&#39;, &#39;đa&#39;, &#39;được&#39;, &#39;khởi_công&#39;, &#39;xây_dựng&#39;, &#39;để&#39;, &#39;sang&#39;, &#39;năm&#39;, &#39;các&#39;, &#39;em&#39;, &#39;có&#39;, &#39;chỗ&#39;, &#39;học&#39;, &#39;nhưng&#39;, &#39;điều&#39;, &#39;đáng&#39;, &#39;nói&#39;, &#39;là&#39;, &#39;đến&#39;, &#39;nay&#39;, &#39;năm_học&#39;, &#39;gần&#39;, &#39;kết_thúc&#39;, &#39;vẫn&#39;, &#39;chưa&#39;, &#39;thấy&#39;, &#39;xây&#39;, &#39;trường&#39;, &#39;nhiều&#39;, &#39;phụ_huynh&#39;, &#39;cảm_thấy&#39;, &#39;không&#39;, &#39;yên_tâm&#39;, &#39;khi&#39;, &#39;hằng&#39;, &#39;ngày&#39;, &#39;con_em&#39;, &#39;họ&#39;, &#39;phải&#39;, &#39;học&#39;, &#39;trong&#39;, &#39;tình_trạng&#39;, &#39;trường&#39;, &#39;lớp&#39;, &#39;tạm_bợ&#39;, &#39;và&#39;, &#39;đi_lại&#39;, &#39;kém&#39;, &#39;an_toàn&#39;, &#39;như_thế&#39;]\n"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toNumVector(X):\n",
    "    NumVectorFull = []\n",
    "    filePath = 'trainVector.npy'\n",
    "    if os.path.isfile(filePath) is False:\n",
    "        for word_array in X:\n",
    "            NumVector = []\n",
    "            for word in wordList:\n",
    "                NumVector.append(word_array.count(word))\n",
    "            NumVectorFull.append(NumVector)\n",
    "        NumVectorFull = np.array(NumVectorFull)\n",
    "        f = open(filePath, 'wb+')\n",
    "        np.save(filePath,NumVectorFull)\n",
    "        f.close()\n",
    "        return NumVectorFull\n",
    "    else:\n",
    "        f = open(filePath)\n",
    "        NumVectorFull = np.load(filePath, allow_pickle = True)\n",
    "        f.close() \n",
    "        return NumVectorFull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "NumVectorFull = toNumVector(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5000\n"
    }
   ],
   "source": [
    "print(len(NumVectorFull))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transLabel(y):\n",
    "    if y == '__CTXH__':\n",
    "        return 0\n",
    "    if y == '__SK__':\n",
    "        return 1\n",
    "    if y == '__TG__':\n",
    "        return 2\n",
    "    if y == '__DS__':\n",
    "        return 3\n",
    "    if y == '__TT__':\n",
    "        return 4\n",
    "    if y == '__KH__':\n",
    "        return 5\n",
    "    if y == '__PL__':\n",
    "        return 6\n",
    "    if y == '__VT__':\n",
    "        return 7\n",
    "    if y == '__KD__':\n",
    "        return 8\n",
    "    if y == '__VH__':\n",
    "        return 9\n",
    "    if y == 0:\n",
    "        return '__CTXH__'\n",
    "    if y == 1:\n",
    "        return '__SK__'\n",
    "    if y == 2:\n",
    "        return '__TG__'\n",
    "    if y == 3:\n",
    "        return '__DS__'\n",
    "    if y == 4:\n",
    "        return '__TT__'\n",
    "    if y == 5:\n",
    "        return '__KH__'\n",
    "    if y == 6:\n",
    "        return '__PL__'\n",
    "    if y == 7:\n",
    "        return '__VT__'\n",
    "    if y == 8:\n",
    "        return '__KD__'\n",
    "    if y == 9:\n",
    "        return '__VH__'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y)):\n",
    "    Y[i] = transLabel(Y[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5000\n"
    }
   ],
   "source": [
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# đã xong phần feature selection, ta có tập train được chia thành 2 phần, tập X là vector đếm số lần xuất hiện của mỗi từ trong wordList trong mỗi văn bản, tập Y là label của mỗi văn bản\n",
    "\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, Y_train, Y_test =  train_test_split(NumVectorFull, Y,test_size=0.2,random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0 0 1 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 1 4 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n"
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, filePath, X_train, Y_train ):\n",
    "    if os.path.isfile(filePath) is False:\n",
    "        modelTrain = model\n",
    "        modelTrain.fit(X_train, Y_train) \n",
    "        Y_predict = modelTrain.predict(X_test)\n",
    "        print(classification_report(Y_test,Y_predict))\n",
    "        pickle.dump(modelTrain, open(filePath, 'wb+'))\n",
    "    else:\n",
    "        model_load = pickle.load(open(filePath, 'rb'))\n",
    "        Y_predict = model_load.predict(X_test)\n",
    "        print(classification_report(Y_test,Y_predict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        99\n           1       1.00      1.00      1.00       106\n           2       1.00      1.00      1.00       102\n           3       1.00      0.99      0.99        92\n           4       1.00      1.00      1.00        82\n           5       0.99      1.00      1.00       117\n           6       1.00      1.00      1.00        89\n           7       1.00      1.00      1.00       107\n           8       1.00      1.00      1.00       105\n           9       1.00      1.00      1.00       101\n\n    accuracy                           1.00      1000\n   macro avg       1.00      1.00      1.00      1000\nweighted avg       1.00      1.00      1.00      1000\n\n"
    }
   ],
   "source": [
    "#random forest\n",
    "train(RandomForestClassifier(max_depth=10000, random_state=0), 'randomforest100.pkl', NumVectorFull, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n           0       0.67      0.61      0.63        99\n           1       0.84      0.92      0.88       106\n           2       0.86      0.88      0.87       102\n           3       0.81      0.80      0.81        92\n           4       0.98      0.98      0.98        82\n           5       0.89      0.75      0.81       117\n           6       0.80      0.91      0.85        89\n           7       0.90      0.83      0.86       107\n           8       0.81      0.90      0.85       105\n           9       0.88      0.86      0.87       101\n\n    accuracy                           0.84      1000\n   macro avg       0.84      0.85      0.84      1000\nweighted avg       0.84      0.84      0.84      1000\n\n"
    }
   ],
   "source": [
    "train(RandomForestClassifier(max_depth=10000, random_state=0), 'randomforest.pkl', X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n           0       0.48      0.65      0.55        99\n           1       0.86      0.82      0.84       106\n           2       0.80      0.87      0.84       102\n           3       0.70      0.75      0.73        92\n           4       0.99      0.95      0.97        82\n           5       0.76      0.64      0.69       117\n           6       0.82      0.79      0.80        89\n           7       0.89      0.77      0.82       107\n           8       0.76      0.68      0.71       105\n           9       0.76      0.81      0.78       101\n\n    accuracy                           0.77      1000\n   macro avg       0.78      0.77      0.77      1000\nweighted avg       0.78      0.77      0.77      1000\n\n"
    }
   ],
   "source": [
    "train(GaussianNB(), 'naivebayes.pkl', X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n           0       0.50      0.75      0.60        99\n           1       0.93      0.77      0.85       106\n           2       0.91      0.87      0.89       102\n           3       0.63      0.83      0.72        92\n           4       0.99      0.89      0.94        82\n           5       0.88      0.79      0.83       117\n           6       0.87      0.85      0.86        89\n           7       0.89      0.73      0.80       107\n           8       0.87      0.80      0.83       105\n           9       0.88      0.83      0.86       101\n\n    accuracy                           0.81      1000\n   macro avg       0.83      0.81      0.82      1000\nweighted avg       0.84      0.81      0.82      1000\n\n"
    }
   ],
   "source": [
    "train(svm.SVC(), 'SVM.pkl', X_train, Y_train)"
   ]
  },
  {
   "source": [
    "now we use 100% of train data to build model\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}